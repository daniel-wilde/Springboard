16:21:52,969 root DEBUG running analyzer now
16:21:56,310 py4j.java_gateway DEBUG GatewayClient.address is deprecated and will be removed in version 1.0. Use GatewayParameters instead.
16:21:56,311 py4j.clientserver DEBUG Command to send: A
f4389fd2d604d4cf75eecdb9684fb93d8e6b0f001e91a1d7c8172906924eba27

16:21:56,402 py4j.clientserver DEBUG Answer received: !yv
16:21:56,402 py4j.clientserver DEBUG Command to send: j
i
rj
org.apache.spark.SparkConf
e

16:21:56,405 py4j.clientserver DEBUG Answer received: !yv
16:21:56,405 py4j.clientserver DEBUG Command to send: j
i
rj
org.apache.spark.api.java.*
e

16:21:56,405 py4j.clientserver DEBUG Answer received: !yv
16:21:56,405 py4j.clientserver DEBUG Command to send: j
i
rj
org.apache.spark.api.python.*
e

16:21:56,406 py4j.clientserver DEBUG Answer received: !yv
16:21:56,406 py4j.clientserver DEBUG Command to send: j
i
rj
org.apache.spark.ml.python.*
e

16:21:56,406 py4j.clientserver DEBUG Answer received: !yv
16:21:56,406 py4j.clientserver DEBUG Command to send: j
i
rj
org.apache.spark.mllib.api.python.*
e

16:21:56,407 py4j.clientserver DEBUG Answer received: !yv
16:21:56,407 py4j.clientserver DEBUG Command to send: j
i
rj
org.apache.spark.resource.*
e

16:21:56,407 py4j.clientserver DEBUG Answer received: !yv
16:21:56,408 py4j.clientserver DEBUG Command to send: j
i
rj
org.apache.spark.sql.*
e

16:21:56,408 py4j.clientserver DEBUG Answer received: !yv
16:21:56,408 py4j.clientserver DEBUG Command to send: j
i
rj
org.apache.spark.sql.api.python.*
e

16:21:56,408 py4j.clientserver DEBUG Answer received: !yv
16:21:56,409 py4j.clientserver DEBUG Command to send: j
i
rj
org.apache.spark.sql.hive.*
e

16:21:56,409 py4j.clientserver DEBUG Answer received: !yv
16:21:56,409 py4j.clientserver DEBUG Command to send: j
i
rj
scala.Tuple2
e

16:21:56,409 py4j.clientserver DEBUG Answer received: !yv
16:21:56,410 py4j.clientserver DEBUG Command to send: r
u
SparkConf
rj
e

16:21:56,413 py4j.clientserver DEBUG Answer received: !ycorg.apache.spark.SparkConf
16:21:56,414 py4j.clientserver DEBUG Command to send: i
org.apache.spark.SparkConf
bTrue
e

16:21:56,426 py4j.clientserver DEBUG Answer received: !yro0
16:21:56,426 py4j.clientserver DEBUG Command to send: c
o0
set
sspark.master
slocal
e

16:21:56,440 py4j.clientserver DEBUG Answer received: !yro1
16:21:56,441 py4j.clientserver DEBUG Command to send: c
o0
set
sspark.app.name
sapp
e

16:21:56,441 py4j.clientserver DEBUG Answer received: !yro2
16:21:56,442 py4j.clientserver DEBUG Command to send: c
o0
contains
sspark.serializer.objectStreamReset
e

16:21:56,442 py4j.clientserver DEBUG Answer received: !ybfalse
16:21:56,442 py4j.clientserver DEBUG Command to send: c
o0
set
sspark.serializer.objectStreamReset
s100
e

16:21:56,443 py4j.clientserver DEBUG Answer received: !yro3
16:21:56,443 py4j.clientserver DEBUG Command to send: c
o0
contains
sspark.rdd.compress
e

16:21:56,443 py4j.clientserver DEBUG Answer received: !ybfalse
16:21:56,444 py4j.clientserver DEBUG Command to send: c
o0
set
sspark.rdd.compress
sTrue
e

16:21:56,444 py4j.clientserver DEBUG Answer received: !yro4
16:21:56,444 py4j.clientserver DEBUG Command to send: c
o0
contains
sspark.master
e

16:21:56,445 py4j.clientserver DEBUG Answer received: !ybtrue
16:21:56,445 py4j.clientserver DEBUG Command to send: c
o0
contains
sspark.app.name
e

16:21:56,445 py4j.clientserver DEBUG Answer received: !ybtrue
16:21:56,446 py4j.clientserver DEBUG Command to send: c
o0
contains
sspark.master
e

16:21:56,446 py4j.clientserver DEBUG Answer received: !ybtrue
16:21:56,447 py4j.clientserver DEBUG Command to send: c
o0
get
sspark.master
e

16:21:56,448 py4j.clientserver DEBUG Answer received: !yslocal
16:21:56,448 py4j.clientserver DEBUG Command to send: c
o0
contains
sspark.app.name
e

16:21:56,448 py4j.clientserver DEBUG Answer received: !ybtrue
16:21:56,449 py4j.clientserver DEBUG Command to send: c
o0
get
sspark.app.name
e

16:21:56,449 py4j.clientserver DEBUG Answer received: !ysapp
16:21:56,449 py4j.clientserver DEBUG Command to send: c
o0
contains
sspark.home
e

16:21:56,450 py4j.clientserver DEBUG Answer received: !ybfalse
16:21:56,450 py4j.clientserver DEBUG Command to send: c
o0
getAll
e

16:21:56,451 py4j.clientserver DEBUG Answer received: !yto5
16:21:56,451 py4j.clientserver DEBUG Command to send: a
e
o5
e

16:21:56,451 py4j.clientserver DEBUG Answer received: !yi7
16:21:56,451 py4j.clientserver DEBUG Command to send: a
g
o5
i0
e

16:21:56,452 py4j.clientserver DEBUG Answer received: !yro6
16:21:56,452 py4j.clientserver DEBUG Command to send: c
o6
_1
e

16:21:56,453 py4j.clientserver DEBUG Answer received: !ysspark.master
16:21:56,453 py4j.clientserver DEBUG Command to send: c
o6
_2
e

16:21:56,453 py4j.clientserver DEBUG Answer received: !yslocal
16:21:56,453 py4j.clientserver DEBUG Command to send: a
e
o5
e

16:21:56,454 py4j.clientserver DEBUG Answer received: !yi7
16:21:56,454 py4j.clientserver DEBUG Command to send: a
g
o5
i1
e

16:21:56,454 py4j.clientserver DEBUG Answer received: !yro7
16:21:56,454 py4j.clientserver DEBUG Command to send: c
o7
_1
e

16:21:56,455 py4j.clientserver DEBUG Answer received: !ysspark.app.name
16:21:56,455 py4j.clientserver DEBUG Command to send: c
o7
_2
e

16:21:56,455 py4j.clientserver DEBUG Answer received: !ysapp
16:21:56,455 py4j.clientserver DEBUG Command to send: a
e
o5
e

16:21:56,456 py4j.clientserver DEBUG Answer received: !yi7
16:21:56,456 py4j.clientserver DEBUG Command to send: a
g
o5
i2
e

16:21:56,456 py4j.clientserver DEBUG Answer received: !yro8
16:21:56,456 py4j.clientserver DEBUG Command to send: c
o8
_1
e

16:21:56,457 py4j.clientserver DEBUG Answer received: !ysspark.rdd.compress
16:21:56,457 py4j.clientserver DEBUG Command to send: c
o8
_2
e

16:21:56,457 py4j.clientserver DEBUG Answer received: !ysTrue
16:21:56,457 py4j.clientserver DEBUG Command to send: a
e
o5
e

16:21:56,458 py4j.clientserver DEBUG Answer received: !yi7
16:21:56,458 py4j.clientserver DEBUG Command to send: a
g
o5
i3
e

16:21:56,458 py4j.clientserver DEBUG Answer received: !yro9
16:21:56,458 py4j.clientserver DEBUG Command to send: c
o9
_1
e

16:21:56,458 py4j.clientserver DEBUG Answer received: !ysspark.serializer.objectStreamReset
16:21:56,459 py4j.clientserver DEBUG Command to send: c
o9
_2
e

16:21:56,459 py4j.clientserver DEBUG Answer received: !ys100
16:21:56,459 py4j.clientserver DEBUG Command to send: a
e
o5
e

16:21:56,459 py4j.clientserver DEBUG Answer received: !yi7
16:21:56,460 py4j.clientserver DEBUG Command to send: a
g
o5
i4
e

16:21:56,460 py4j.clientserver DEBUG Answer received: !yro10
16:21:56,460 py4j.clientserver DEBUG Command to send: c
o10
_1
e

16:21:56,460 py4j.clientserver DEBUG Answer received: !ysspark.submit.pyFiles
16:21:56,460 py4j.clientserver DEBUG Command to send: c
o10
_2
e

16:21:56,461 py4j.clientserver DEBUG Answer received: !ys
16:21:56,461 py4j.clientserver DEBUG Command to send: a
e
o5
e

16:21:56,461 py4j.clientserver DEBUG Answer received: !yi7
16:21:56,461 py4j.clientserver DEBUG Command to send: a
g
o5
i5
e

16:21:56,461 py4j.clientserver DEBUG Answer received: !yro11
16:21:56,461 py4j.clientserver DEBUG Command to send: c
o11
_1
e

16:21:56,462 py4j.clientserver DEBUG Answer received: !ysspark.submit.deployMode
16:21:56,462 py4j.clientserver DEBUG Command to send: c
o11
_2
e

16:21:56,463 py4j.clientserver DEBUG Answer received: !ysclient
16:21:56,463 py4j.clientserver DEBUG Command to send: a
e
o5
e

16:21:56,463 py4j.clientserver DEBUG Answer received: !yi7
16:21:56,463 py4j.clientserver DEBUG Command to send: a
g
o5
i6
e

16:21:56,463 py4j.clientserver DEBUG Answer received: !yro12
16:21:56,464 py4j.clientserver DEBUG Command to send: c
o12
_1
e

16:21:56,464 py4j.clientserver DEBUG Answer received: !ysspark.ui.showConsoleProgress
16:21:56,464 py4j.clientserver DEBUG Command to send: c
o12
_2
e

16:21:56,465 py4j.clientserver DEBUG Answer received: !ystrue
16:21:56,465 py4j.clientserver DEBUG Command to send: a
e
o5
e

16:21:56,465 py4j.clientserver DEBUG Answer received: !yi7
16:21:56,465 py4j.clientserver DEBUG Command to send: r
u
JavaSparkContext
rj
e

16:21:56,484 py4j.clientserver DEBUG Answer received: !ycorg.apache.spark.api.java.JavaSparkContext
16:21:56,484 py4j.clientserver DEBUG Command to send: i
org.apache.spark.api.java.JavaSparkContext
ro0
e

16:21:57,315 py4j.clientserver DEBUG Command to send: A
f4389fd2d604d4cf75eecdb9684fb93d8e6b0f001e91a1d7c8172906924eba27

16:21:57,316 py4j.clientserver DEBUG Answer received: !yv
16:21:57,316 py4j.clientserver DEBUG Command to send: m
d
o1
e

16:21:57,316 py4j.clientserver DEBUG Answer received: !yv
16:21:57,316 py4j.clientserver DEBUG Command to send: m
d
o2
e

16:21:57,316 py4j.clientserver DEBUG Answer received: !yv
16:21:57,316 py4j.clientserver DEBUG Command to send: m
d
o3
e

16:21:57,317 py4j.clientserver DEBUG Answer received: !yv
16:21:57,317 py4j.clientserver DEBUG Command to send: m
d
o4
e

16:21:57,317 py4j.clientserver DEBUG Answer received: !yv
16:21:57,317 py4j.clientserver DEBUG Command to send: m
d
o5
e

16:21:57,317 py4j.clientserver DEBUG Answer received: !yv
16:22:00,197 py4j.clientserver DEBUG Answer received: !yro13
16:22:00,198 py4j.clientserver DEBUG Command to send: c
o13
sc
e

16:22:00,202 py4j.clientserver DEBUG Answer received: !yro14
16:22:00,202 py4j.clientserver DEBUG Command to send: c
o14
conf
e

16:22:00,224 py4j.clientserver DEBUG Answer received: !yro15
16:22:00,231 py4j.clientserver DEBUG Command to send: r
u
PythonAccumulatorV2
rj
e

16:22:00,235 py4j.clientserver DEBUG Answer received: !ycorg.apache.spark.api.python.PythonAccumulatorV2
16:22:00,235 py4j.clientserver DEBUG Command to send: i
org.apache.spark.api.python.PythonAccumulatorV2
s127.0.0.1
i55146
sf4389fd2d604d4cf75eecdb9684fb93d8e6b0f001e91a1d7c8172906924eba27
e

16:22:00,236 py4j.clientserver DEBUG Answer received: !yro16
16:22:00,236 py4j.clientserver DEBUG Command to send: c
o13
sc
e

16:22:00,237 py4j.clientserver DEBUG Answer received: !yro17
16:22:00,237 py4j.clientserver DEBUG Command to send: c
o17
register
ro16
e

16:22:00,241 py4j.clientserver DEBUG Answer received: !yv
16:22:00,241 py4j.clientserver DEBUG Command to send: r
u
PythonUtils
rj
e

16:22:00,242 py4j.clientserver DEBUG Answer received: !ycorg.apache.spark.api.python.PythonUtils
16:22:00,242 py4j.clientserver DEBUG Command to send: r
m
org.apache.spark.api.python.PythonUtils
isEncryptionEnabled
e

16:22:00,243 py4j.clientserver DEBUG Answer received: !ym
16:22:00,243 py4j.clientserver DEBUG Command to send: c
z:org.apache.spark.api.python.PythonUtils
isEncryptionEnabled
ro13
e

16:22:00,245 py4j.clientserver DEBUG Answer received: !ybfalse
16:22:00,245 py4j.clientserver DEBUG Command to send: r
u
PythonUtils
rj
e

16:22:00,246 py4j.clientserver DEBUG Answer received: !ycorg.apache.spark.api.python.PythonUtils
16:22:00,246 py4j.clientserver DEBUG Command to send: r
m
org.apache.spark.api.python.PythonUtils
getPythonAuthSocketTimeout
e

16:22:00,247 py4j.clientserver DEBUG Answer received: !ym
16:22:00,247 py4j.clientserver DEBUG Command to send: c
z:org.apache.spark.api.python.PythonUtils
getPythonAuthSocketTimeout
ro13
e

16:22:00,247 py4j.clientserver DEBUG Answer received: !yL15
16:22:00,247 py4j.clientserver DEBUG Command to send: r
u
PythonUtils
rj
e

16:22:00,248 py4j.clientserver DEBUG Answer received: !ycorg.apache.spark.api.python.PythonUtils
16:22:00,248 py4j.clientserver DEBUG Command to send: r
m
org.apache.spark.api.python.PythonUtils
getSparkBufferSize
e

16:22:00,249 py4j.clientserver DEBUG Answer received: !ym
16:22:00,249 py4j.clientserver DEBUG Command to send: c
z:org.apache.spark.api.python.PythonUtils
getSparkBufferSize
ro13
e

16:22:00,249 py4j.clientserver DEBUG Answer received: !yi65536
16:22:00,249 py4j.clientserver DEBUG Command to send: r
u
org
rj
e

16:22:00,253 py4j.clientserver DEBUG Answer received: !yp
16:22:00,253 py4j.clientserver DEBUG Command to send: r
u
org.apache
rj
e

16:22:00,254 py4j.clientserver DEBUG Answer received: !yp
16:22:00,254 py4j.clientserver DEBUG Command to send: r
u
org.apache.spark
rj
e

16:22:00,255 py4j.clientserver DEBUG Answer received: !yp
16:22:00,255 py4j.clientserver DEBUG Command to send: r
u
org.apache.spark.SparkFiles
rj
e

16:22:00,256 py4j.clientserver DEBUG Answer received: !ycorg.apache.spark.SparkFiles
16:22:00,256 py4j.clientserver DEBUG Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

16:22:00,257 py4j.clientserver DEBUG Answer received: !ym
16:22:00,257 py4j.clientserver DEBUG Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

16:22:00,258 py4j.clientserver DEBUG Answer received: !ysC:\\Users\\danie\\AppData\\Local\\Temp\\spark-10fa0bc5-b92b-4d6b-979d-29222ad634cd\\userFiles-31e26aee-bf11-4632-b899-d55f880231a6
16:22:00,259 py4j.clientserver DEBUG Command to send: c
o15
get
sspark.submit.pyFiles
s
e

16:22:00,259 py4j.clientserver DEBUG Answer received: !ys
16:22:00,259 py4j.clientserver DEBUG Command to send: r
u
org
rj
e

16:22:00,274 py4j.clientserver DEBUG Answer received: !yp
16:22:00,274 py4j.clientserver DEBUG Command to send: r
u
org.apache
rj
e

16:22:00,275 py4j.clientserver DEBUG Answer received: !yp
16:22:00,275 py4j.clientserver DEBUG Command to send: r
u
org.apache.spark
rj
e

16:22:00,276 py4j.clientserver DEBUG Answer received: !yp
16:22:00,276 py4j.clientserver DEBUG Command to send: r
u
org.apache.spark.util
rj
e

16:22:00,277 py4j.clientserver DEBUG Answer received: !yp
16:22:00,277 py4j.clientserver DEBUG Command to send: r
u
org.apache.spark.util.Utils
rj
e

16:22:00,280 py4j.clientserver DEBUG Answer received: !ycorg.apache.spark.util.Utils
16:22:00,280 py4j.clientserver DEBUG Command to send: r
m
org.apache.spark.util.Utils
getLocalDir
e

16:22:00,284 py4j.clientserver DEBUG Answer received: !ym
16:22:00,284 py4j.clientserver DEBUG Command to send: c
o13
sc
e

16:22:00,284 py4j.clientserver DEBUG Answer received: !yro18
16:22:00,285 py4j.clientserver DEBUG Command to send: c
o18
conf
e

16:22:00,285 py4j.clientserver DEBUG Answer received: !yro19
16:22:00,285 py4j.clientserver DEBUG Command to send: c
z:org.apache.spark.util.Utils
getLocalDir
ro19
e

16:22:00,286 py4j.clientserver DEBUG Answer received: !ysC:\\Users\\danie\\AppData\\Local\\Temp\\spark-10fa0bc5-b92b-4d6b-979d-29222ad634cd
16:22:00,286 py4j.clientserver DEBUG Command to send: r
u
org
rj
e

16:22:00,289 py4j.clientserver DEBUG Answer received: !yp
16:22:00,290 py4j.clientserver DEBUG Command to send: r
u
org.apache
rj
e

16:22:00,290 py4j.clientserver DEBUG Answer received: !yp
16:22:00,291 py4j.clientserver DEBUG Command to send: r
u
org.apache.spark
rj
e

16:22:00,291 py4j.clientserver DEBUG Answer received: !yp
16:22:00,291 py4j.clientserver DEBUG Command to send: r
u
org.apache.spark.util
rj
e

16:22:00,292 py4j.clientserver DEBUG Answer received: !yp
16:22:00,292 py4j.clientserver DEBUG Command to send: r
u
org.apache.spark.util.Utils
rj
e

16:22:00,292 py4j.clientserver DEBUG Answer received: !ycorg.apache.spark.util.Utils
16:22:00,292 py4j.clientserver DEBUG Command to send: r
m
org.apache.spark.util.Utils
createTempDir
e

16:22:00,293 py4j.clientserver DEBUG Answer received: !ym
16:22:00,293 py4j.clientserver DEBUG Command to send: c
z:org.apache.spark.util.Utils
createTempDir
sC:\\Users\\danie\\AppData\\Local\\Temp\\spark-10fa0bc5-b92b-4d6b-979d-29222ad634cd
spyspark
e

16:22:00,295 py4j.clientserver DEBUG Answer received: !yro20
16:22:00,295 py4j.clientserver DEBUG Command to send: c
o20
getAbsolutePath
e

16:22:00,296 py4j.clientserver DEBUG Answer received: !ysC:\\Users\\danie\\AppData\\Local\\Temp\\spark-10fa0bc5-b92b-4d6b-979d-29222ad634cd\\pyspark-1703e6ca-e5ec-4060-b308-d7772b2c569f
16:22:00,296 py4j.clientserver DEBUG Command to send: c
o15
get
sspark.python.profile
sfalse
e

16:22:00,297 py4j.clientserver DEBUG Answer received: !ysfalse
16:22:00,297 py4j.clientserver DEBUG Command to send: r
u
SparkSession
rj
e

16:22:00,332 py4j.clientserver DEBUG Answer received: !ycorg.apache.spark.sql.SparkSession
16:22:00,332 py4j.clientserver DEBUG Command to send: r
m
org.apache.spark.sql.SparkSession
getDefaultSession
e

16:22:00,344 py4j.clientserver DEBUG Command to send: m
d
o0
e

16:22:00,345 py4j.clientserver DEBUG Answer received: !yv
16:22:00,345 py4j.clientserver DEBUG Command to send: m
d
o6
e

16:22:00,345 py4j.clientserver DEBUG Answer received: !yv
16:22:00,345 py4j.clientserver DEBUG Command to send: m
d
o7
e

16:22:00,346 py4j.clientserver DEBUG Answer received: !yv
16:22:00,346 py4j.clientserver DEBUG Command to send: m
d
o8
e

16:22:00,346 py4j.clientserver DEBUG Answer received: !yv
16:22:00,346 py4j.clientserver DEBUG Command to send: m
d
o9
e

16:22:00,346 py4j.clientserver DEBUG Answer received: !yv
16:22:00,346 py4j.clientserver DEBUG Command to send: m
d
o10
e

16:22:00,347 py4j.clientserver DEBUG Answer received: !yv
16:22:00,347 py4j.clientserver DEBUG Command to send: m
d
o11
e

16:22:00,347 py4j.clientserver DEBUG Answer received: !yv
16:22:00,347 py4j.clientserver DEBUG Command to send: m
d
o12
e

16:22:00,347 py4j.clientserver DEBUG Answer received: !yv
16:22:00,347 py4j.clientserver DEBUG Command to send: m
d
o14
e

16:22:00,347 py4j.clientserver DEBUG Answer received: !yv
16:22:00,369 py4j.clientserver DEBUG Answer received: !ym
16:22:00,370 py4j.clientserver DEBUG Command to send: c
z:org.apache.spark.sql.SparkSession
getDefaultSession
e

16:22:00,371 py4j.clientserver DEBUG Answer received: !yro21
16:22:00,371 py4j.clientserver DEBUG Command to send: c
o21
isDefined
e

16:22:00,372 py4j.clientserver DEBUG Answer received: !ybfalse
16:22:00,372 py4j.clientserver DEBUG Command to send: r
u
SparkSession
rj
e

16:22:00,374 py4j.clientserver DEBUG Answer received: !ycorg.apache.spark.sql.SparkSession
16:22:00,375 py4j.clientserver DEBUG Command to send: c
o13
sc
e

16:22:00,375 py4j.clientserver DEBUG Answer received: !yro22
16:22:00,375 py4j.clientserver DEBUG Command to send: i
org.apache.spark.sql.SparkSession
ro22
e

16:22:00,475 py4j.clientserver DEBUG Answer received: !yro23
16:22:00,476 py4j.clientserver DEBUG Command to send: c
o23
sqlContext
e

16:22:00,476 py4j.clientserver DEBUG Answer received: !yro24
16:22:00,476 py4j.clientserver DEBUG Command to send: r
u
SparkSession
rj
e

16:22:00,479 py4j.clientserver DEBUG Answer received: !ycorg.apache.spark.sql.SparkSession
16:22:00,479 py4j.clientserver DEBUG Command to send: r
m
org.apache.spark.sql.SparkSession
setDefaultSession
e

16:22:00,479 py4j.clientserver DEBUG Answer received: !ym
16:22:00,479 py4j.clientserver DEBUG Command to send: c
z:org.apache.spark.sql.SparkSession
setDefaultSession
ro23
e

16:22:00,480 py4j.clientserver DEBUG Answer received: !yv
16:22:00,480 py4j.clientserver DEBUG Command to send: r
u
SparkSession
rj
e

16:22:00,482 py4j.clientserver DEBUG Answer received: !ycorg.apache.spark.sql.SparkSession
16:22:00,482 py4j.clientserver DEBUG Command to send: r
m
org.apache.spark.sql.SparkSession
setActiveSession
e

16:22:00,482 py4j.clientserver DEBUG Answer received: !ym
16:22:00,482 py4j.clientserver DEBUG Command to send: c
z:org.apache.spark.sql.SparkSession
setActiveSession
ro23
e

16:22:00,483 py4j.clientserver DEBUG Answer received: !yv
16:22:00,483 py4j.clientserver DEBUG Command to send: c
o23
sessionState
e

16:22:01,641 py4j.clientserver DEBUG Answer received: !yro25
16:22:01,641 py4j.clientserver DEBUG Command to send: c
o25
conf
e

16:22:01,642 py4j.clientserver DEBUG Answer received: !yro26
16:22:01,642 py4j.clientserver DEBUG Command to send: c
o26
setConfString
sspark.master
slocal
e

16:22:01,644 py4j.clientserver DEBUG Answer received: !yv
16:22:01,644 py4j.clientserver DEBUG Command to send: c
o23
sessionState
e

16:22:01,645 py4j.clientserver DEBUG Answer received: !yro27
16:22:01,645 py4j.clientserver DEBUG Command to send: c
o27
conf
e

16:22:01,645 py4j.clientserver DEBUG Answer received: !yro28
16:22:01,645 py4j.clientserver DEBUG Command to send: c
o28
setConfString
sspark.app.name
sapp
e

16:22:01,645 py4j.clientserver DEBUG Answer received: !yv
16:22:01,646 py4j.clientserver DEBUG Command to send: c
o13
setLogLevel
sWARN
e

16:22:01,647 py4j.clientserver DEBUG Answer received: !yv
16:22:01,647 py4j.clientserver DEBUG Command to send: c
o24
read
e

16:22:01,656 py4j.clientserver DEBUG Answer received: !yro29
16:22:01,656 py4j.clientserver DEBUG Command to send: r
u
PythonUtils
rj
e

16:22:01,657 py4j.clientserver DEBUG Answer received: !ycorg.apache.spark.api.python.PythonUtils
16:22:01,657 py4j.clientserver DEBUG Command to send: r
m
org.apache.spark.api.python.PythonUtils
toSeq
e

16:22:01,657 py4j.clientserver DEBUG Answer received: !ym
16:22:01,657 py4j.clientserver DEBUG Command to send: i
java.util.ArrayList
e

16:22:01,658 py4j.clientserver DEBUG Answer received: !ylo30
16:22:01,658 py4j.clientserver DEBUG Command to send: c
o30
add
sC:\\GitRepos\\Springboard\\Capstone\\output\\divs_and_prices\\
e

16:22:01,659 py4j.clientserver DEBUG Answer received: !ybtrue
16:22:01,659 py4j.clientserver DEBUG Command to send: c
z:org.apache.spark.api.python.PythonUtils
toSeq
ro30
e

16:22:01,659 py4j.clientserver DEBUG Answer received: !yro31
16:22:01,659 py4j.clientserver DEBUG Command to send: c
o29
parquet
ro31
e

16:22:02,364 py4j.clientserver DEBUG Command to send: m
d
o30
e

16:22:02,364 py4j.clientserver DEBUG Answer received: !yv
16:22:09,355 py4j.clientserver DEBUG Answer received: !yro32
16:22:09,355 py4j.clientserver DEBUG Command to send: c
o32
createOrReplaceTempView
sall_data
e

16:22:09,789 py4j.clientserver DEBUG Answer received: !yv
16:22:09,789 py4j.clientserver DEBUG Command to send: c
o23
sql
s\n                SELECT \n                    b.Ticker,\n                    b.FreqType, \n                    b.ExDivDate,\n                    b.ExDivDays AS b_ExDivDays,\n                    b.AvgPrice AS b_AvgPrice,\n                    b.SandPAvgPrice AS b_SandPAvgPrice,\n                    a.ExDivDays AS a_ExDivDays,\n                    a.AvgPrice AS a_AvgPrice,\n                    a.SandPAvgPrice AS a_SandPAvgPrice,\n                    ((a.AvgPrice + a.AdjAmount) - b.AvgPrice) / b.AvgPrice AS TotalReturn,\n                    ((a.SandPAvgPrice + a.SandPAvgPrice) - b.SandPAvgPrice) / b.SandPAvgPrice AS TotalSandPReturn\n                FROM all_data b\n                    LEFT JOIN all_data a ON b.Ticker = a.Ticker\n                        AND b.ExDivDate = b.ExDivDate\n                WHERE b.ExDivDays = 1 \n                    AND a.ExDivDate = 0\n                
e

16:22:09,987 py4j.clientserver DEBUG Answer received: !xro33
16:22:09,987 py4j.clientserver DEBUG Command to send: c
o33
toString
e

16:22:09,990 py4j.clientserver DEBUG Answer received: !ysorg.apache.spark.sql.AnalysisException: cannot resolve '(a.ExDivDate = 0)' due to data type mismatch: differing types in '(a.ExDivDate = 0)' (timestamp and int).; line 18 pos 24;\n'Project ['b.Ticker, 'b.FreqType, 'b.ExDivDate, 'b.ExDivDays AS b_ExDivDays#16, 'b.AvgPrice AS b_AvgPrice#17, 'b.SandPAvgPrice AS b_SandPAvgPrice#18, 'a.ExDivDays AS a_ExDivDays#19, 'a.AvgPrice AS a_AvgPrice#20, 'a.SandPAvgPrice AS a_SandPAvgPrice#21, ((('a.AvgPrice + 'a.AdjAmount) - 'b.AvgPrice) / 'b.AvgPrice) AS TotalReturn#22, ((('a.SandPAvgPrice + 'a.SandPAvgPrice) - 'b.SandPAvgPrice) / 'b.SandPAvgPrice) AS TotalSandPReturn#23]\n+- 'Filter ((ExDivDays#4 = 1) AND (ExDivDate#25 = 0))\n   +- Join LeftOuter, ((Ticker#7 = Ticker#31) AND (ExDivDate#1 = ExDivDate#1))\n      :- SubqueryAlias b\n      :  +- SubqueryAlias all_data\n      :     +- View (`all_data`, [FreqType#0,ExDivDate#1,AdjAmount#2,PriceDate#3,ExDivDays#4,AvgPrice#5,SandPAvgPrice#6,Ticker#7])\n      :        +- Relation [FreqType#0,ExDivDate#1,AdjAmount#2,PriceDate#3,ExDivDays#4,AvgPrice#5,SandPAvgPrice#6,Ticker#7] parquet\n      +- SubqueryAlias a\n         +- SubqueryAlias all_data\n            +- View (`all_data`, [FreqType#24,ExDivDate#25,AdjAmount#26,PriceDate#27,ExDivDays#28,AvgPrice#29,SandPAvgPrice#30,Ticker#31])\n               +- Relation [FreqType#24,ExDivDate#25,AdjAmount#26,PriceDate#27,ExDivDays#28,AvgPrice#29,SandPAvgPrice#30,Ticker#31] parquet\n
16:22:09,991 py4j.clientserver DEBUG Command to send: c
o33
getCause
e

16:22:09,991 py4j.clientserver DEBUG Answer received: !yn
16:22:09,991 py4j.clientserver DEBUG Command to send: r
u
org
rj
e

16:22:09,995 py4j.clientserver DEBUG Answer received: !yp
16:22:09,995 py4j.clientserver DEBUG Command to send: r
u
org.apache
rj
e

16:22:09,996 py4j.clientserver DEBUG Answer received: !yp
16:22:09,996 py4j.clientserver DEBUG Command to send: r
u
org.apache.spark
rj
e

16:22:09,997 py4j.clientserver DEBUG Answer received: !yp
16:22:09,997 py4j.clientserver DEBUG Command to send: r
u
org.apache.spark.util
rj
e

16:22:09,997 py4j.clientserver DEBUG Answer received: !yp
16:22:09,998 py4j.clientserver DEBUG Command to send: r
u
org.apache.spark.util.Utils
rj
e

16:22:09,998 py4j.clientserver DEBUG Answer received: !ycorg.apache.spark.util.Utils
16:22:09,998 py4j.clientserver DEBUG Command to send: r
m
org.apache.spark.util.Utils
exceptionString
e

16:22:09,998 py4j.clientserver DEBUG Answer received: !ym
16:22:09,998 py4j.clientserver DEBUG Command to send: c
z:org.apache.spark.util.Utils
exceptionString
ro33
e

16:22:10,3 py4j.clientserver DEBUG Answer received: !ysorg.apache.spark.sql.AnalysisException: cannot resolve '(a.ExDivDate = 0)' due to data type mismatch: differing types in '(a.ExDivDate = 0)' (timestamp and int).; line 18 pos 24;\n'Project ['b.Ticker, 'b.FreqType, 'b.ExDivDate, 'b.ExDivDays AS b_ExDivDays#16, 'b.AvgPrice AS b_AvgPrice#17, 'b.SandPAvgPrice AS b_SandPAvgPrice#18, 'a.ExDivDays AS a_ExDivDays#19, 'a.AvgPrice AS a_AvgPrice#20, 'a.SandPAvgPrice AS a_SandPAvgPrice#21, ((('a.AvgPrice + 'a.AdjAmount) - 'b.AvgPrice) / 'b.AvgPrice) AS TotalReturn#22, ((('a.SandPAvgPrice + 'a.SandPAvgPrice) - 'b.SandPAvgPrice) / 'b.SandPAvgPrice) AS TotalSandPReturn#23]\n+- 'Filter ((ExDivDays#4 = 1) AND (ExDivDate#25 = 0))\n   +- Join LeftOuter, ((Ticker#7 = Ticker#31) AND (ExDivDate#1 = ExDivDate#1))\n      :- SubqueryAlias b\n      :  +- SubqueryAlias all_data\n      :     +- View (`all_data`, [FreqType#0,ExDivDate#1,AdjAmount#2,PriceDate#3,ExDivDays#4,AvgPrice#5,SandPAvgPrice#6,Ticker#7])\n      :        +- Relation [FreqType#0,ExDivDate#1,AdjAmount#2,PriceDate#3,ExDivDays#4,AvgPrice#5,SandPAvgPrice#6,Ticker#7] parquet\n      +- SubqueryAlias a\n         +- SubqueryAlias all_data\n            +- View (`all_data`, [FreqType#24,ExDivDate#25,AdjAmount#26,PriceDate#27,ExDivDays#28,AvgPrice#29,SandPAvgPrice#30,Ticker#31])\n               +- Relation [FreqType#24,ExDivDate#25,AdjAmount#26,PriceDate#27,ExDivDays#28,AvgPrice#29,SandPAvgPrice#30,Ticker#31] parquet\n\r\n	at org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)\r\n	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$$nestedInanonfun$checkAnalysis$1$2.applyOrElse(CheckAnalysis.scala:190)\r\n	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$$nestedInanonfun$checkAnalysis$1$2.applyOrElse(CheckAnalysis.scala:175)\r\n	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformUpWithPruning$2(TreeNode.scala:535)\r\n	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:82)\r\n	at org.apache.spark.sql.catalyst.trees.TreeNode.transformUpWithPruning(TreeNode.scala:535)\r\n	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformUpWithPruning$1(TreeNode.scala:532)\r\n	at org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1150)\r\n	at org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1147)\r\n	at org.apache.spark.sql.catalyst.expressions.BinaryExpression.mapChildren(Expression.scala:555)\r\n	at org.apache.spark.sql.catalyst.trees.TreeNode.transformUpWithPruning(TreeNode.scala:532)\r\n	at org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$transformExpressionsUpWithPruning$1(QueryPlan.scala:181)\r\n	at org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$mapExpressions$1(QueryPlan.scala:193)\r\n	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:82)\r\n	at org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpression$1(QueryPlan.scala:193)\r\n	at org.apache.spark.sql.catalyst.plans.QueryPlan.recursiveTransform$1(QueryPlan.scala:204)\r\n	at org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$mapExpressions$4(QueryPlan.scala:214)\r\n	at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:323)\r\n	at org.apache.spark.sql.catalyst.plans.QueryPlan.mapExpressions(QueryPlan.scala:214)\r\n	at org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsUpWithPruning(QueryPlan.scala:181)\r\n	at org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsUp(QueryPlan.scala:161)\r\n	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1(CheckAnalysis.scala:175)\r\n	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1$adapted(CheckAnalysis.scala:94)\r\n	at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:263)\r\n	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:262)\r\n	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:262)\r\n	at scala.collection.Iterator.foreach(Iterator.scala:943)\r\n	at scala.collection.Iterator.foreach$(Iterator.scala:943)\r\n	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\r\n	at scala.collection.IterableLike.foreach(IterableLike.scala:74)\r\n	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)\r\n	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)\r\n	at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:262)\r\n	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:94)\r\n	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:91)\r\n	at org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:182)\r\n	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:205)\r\n	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\r\n	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:202)\r\n	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:88)\r\n	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:111)\r\n	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:196)\r\n	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\r\n	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:196)\r\n	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:88)\r\n	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:86)\r\n	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:78)\r\n	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:98)\r\n	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\r\n	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\r\n	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\r\n	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\r\n	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\r\n	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n	at java.lang.reflect.Method.invoke(Method.java:498)\r\n	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n	at py4j.Gateway.invoke(Gateway.java:282)\r\n	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n	at py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n	at java.lang.Thread.run(Thread.java:748)\r\n
16:22:10,23 py4j.clientserver DEBUG Command to send: r
u
org
rj
e

16:22:10,27 py4j.clientserver DEBUG Answer received: !yp
16:22:10,27 py4j.clientserver DEBUG Command to send: r
u
org.apache
rj
e

16:22:10,28 py4j.clientserver DEBUG Answer received: !yp
16:22:10,28 py4j.clientserver DEBUG Command to send: r
u
org.apache.spark
rj
e

16:22:10,30 py4j.clientserver DEBUG Answer received: !yp
16:22:10,30 py4j.clientserver DEBUG Command to send: r
u
org.apache.spark.sql
rj
e

16:22:10,31 py4j.clientserver DEBUG Answer received: !yp
16:22:10,31 py4j.clientserver DEBUG Command to send: r
u
org.apache.spark.sql.internal
rj
e

16:22:10,32 py4j.clientserver DEBUG Answer received: !yp
16:22:10,32 py4j.clientserver DEBUG Command to send: r
u
org.apache.spark.sql.internal.SQLConf
rj
e

16:22:10,32 py4j.clientserver DEBUG Answer received: !ycorg.apache.spark.sql.internal.SQLConf
16:22:10,32 py4j.clientserver DEBUG Command to send: r
m
org.apache.spark.sql.internal.SQLConf
get
e

16:22:10,33 py4j.clientserver DEBUG Answer received: !ym
16:22:10,33 py4j.clientserver DEBUG Command to send: c
z:org.apache.spark.sql.internal.SQLConf
get
e

16:22:10,33 py4j.clientserver DEBUG Answer received: !yro34
16:22:10,33 py4j.clientserver DEBUG Command to send: c
o34
pysparkJVMStacktraceEnabled
e

16:22:10,34 py4j.clientserver DEBUG Answer received: !ybfalse
